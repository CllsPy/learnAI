# -*- coding: utf-8 -*-
"""mul-modal-ai-app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_umIrIo_AaQQeneFjqhvZMBeGKrSUrMT
"""

# Commented out IPython magic to ensure Python compatibility.
# ## import basic libs
# %%capture
# !pip install transformers langchain huggingface_hub accelerate bitsndbyts pydub
# !pip install langchain-huggingface

import os
from google.colab import userdata

sec_key = userdata.get('HF_TOKEN')
os.environ['HUGGINGFACEHUB_API_TOKEN'] = sec_key

from transformers import pipeline

## create img2text func
def im2tx(url):

    # Use a pipeline as a high-level helper
    image2text = pipeline(
        "image-to-text",
        model="Salesforce/blip-image-captioning-large")

    img_txt = image2text(url)[0]['generated_text']

    return img_txt

text = im2tx('https://media.npr.org/assets/img/2022/11/04/gettyimages-1183414292-1-_slide-30784f99ac10f059c242d37e91d05ead475854f4.jpg')

from langchain_huggingface import HuggingFaceEndpoint

## create def to generate the lore
def createLore(text, id):
    llm = HuggingFaceEndpoint(
        repo_id=id,
        max_length=128,
        temperature=0.7,
        token=sec_key)

    prompt = f'you are a write, your task is write a histor about {text}'
    textResult = llm.invoke(prompt)
    return textResult

repo_id="mistralai/Mistral-7B-Instruct-v0.2"
lore = createLore(text, repo_id)

lore