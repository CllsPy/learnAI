{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Objetivo\n",
        "O objetivo deste notebook é demostrar com código as etapas para acessar e utilizar o Llama-2b para a sumarização de um RSE (Relatório de Saúde Eletrônico)."
      ],
      "metadata": {
        "id": "4mXIe_MgtcEN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autenticação"
      ],
      "metadata": {
        "id": "NXMDczJAtvW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Packages"
      ],
      "metadata": {
        "id": "PCkcPTd8uHKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers langchain accelerate # langchain\n",
        "!pip install gradio"
      ],
      "metadata": {
        "id": "7P90aC3vtxvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "from  langchain import LLMChain, HuggingFacePipeline, PromptTemplate"
      ],
      "metadata": {
        "id": "0TpjalxSudNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HuggingFace - Login"
      ],
      "metadata": {
        "id": "0eMEqFhiuMGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Permissão para acessar o modelo\n",
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "lS5682t0t84W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Template"
      ],
      "metadata": {
        "id": "OoXMVywSukJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Chamar o modelo Llma-2b\n",
        "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)"
      ],
      "metadata": {
        "id": "yNbG7anUvB5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Configurar parâmetros\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\",\n",
        "    max_length=3000,\n",
        "    do_sample=True,\n",
        "    top_k=10,\n",
        "    num_return_sequences=1,\n",
        "    eos_token_id=tokenizer.eos_token_id\n",
        ")"
      ],
      "metadata": {
        "id": "753npTKcum6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Usar HuggingFacePipeline para facilitar interação com modelo\n",
        "llm = HuggingFacePipeline(pipeline = pipeline, model_kwargs = {'temperature':0}) # Facilita passar os parâmetros para o Llama-2b\n",
        "\n",
        "# Denifir pedido\n",
        "template = \"\"\"\n",
        "              Sumarieze o texto\n",
        "              ```{text}```\n",
        "              SUMMARY:\n",
        "           \"\"\"\n",
        "# Passar template ao modelo\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)"
      ],
      "metadata": {
        "id": "Vqqu__IXvALj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testa - Sem Interface"
      ],
      "metadata": {
        "id": "Wb1pMb2QvtJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Conteúdo para ser sumarizado\n",
        "text = \"\"\"\n",
        "1. Histórico Médico:\n",
        "- Condições médicas pré-existentes: Hipertensão arterial\n",
        "- Cirurgias anteriores: Apendicectomia em 2005\n",
        "- Alergias: Nenhuma conhecida\n",
        "- Medicamentos em uso atualmente: Losartana 50mg uma vez ao dia\n",
        "2. Registros de Consultas:\n",
        "- Data e hora da consulta: 02/05/2024, 10:00\n",
        "- Nome do médico: Dra. Ana Santos\n",
        "- Diagnóstico: Hipertensão controlada, sem complicações\n",
        "- Tratamento prescrito: Continuar com a medicação atual, monitorar pressão arterial regularmente\n",
        "- Recomendações médicas: Dieta balanceada, redução do consumo de sal e prática regular de exercícios\n",
        "3. Exames e Resultados:\n",
        "- Tipos de exames realizados: Hemograma completo, perfil lipídico\n",
        "- Resultados dos exames: Hemoglobina: 14 g/dL, Colesterol total: 190 mg/dL, HDL: 50 mg/dL, LDL: 120 mg/dL\n",
        "- Data dos exames: 28/04/2024\n",
        "- Nome do laboratório ou instituição onde os exames foram realizados: Laboratório ABC\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "8vbLh9h7vsdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interface com Gradio"
      ],
      "metadata": {
        "id": "V_NfXdRR4nU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import re\n",
        "\n",
        "def deploy(text):\n",
        "    answer = llm_chain.invoke(text)\n",
        "\n",
        "    # Access the 'text' key from the dictionary\n",
        "    answer_text = answer['text']\n",
        "\n",
        "    # Remove unnecessary whitespaces and newlines\n",
        "    answer_text = re.sub(r'\\n\\s+', '\\n', answer_text.strip())\n",
        "\n",
        "    # Replace Markdown list items with bullet points\n",
        "    answer_text = re.sub(r'\\n\\s*-\\s*', '\\n* ', answer_text)\n",
        "\n",
        "    # Replace inline code blocks with backticks\n",
        "    answer_text = re.sub(r'```', '`', answer_text)\n",
        "\n",
        "    # Add proper indentation for the summary section\n",
        "    summary_start = answer_text.find('SUMMARY:')\n",
        "    answer_text = answer_text[:summary_start] + '\\n\\nSUMMARY:\\n' + answer_text[summary_start + len('SUMMARY:'):].strip()\n",
        "\n",
        "    return answer_text"
      ],
      "metadata": {
        "id": "ncCXH9nW3lTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deploy(text)"
      ],
      "metadata": {
        "id": "FNMJNrWs4icY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo = gr.Interface(fn=deploy, inputs=\"text\", outputs=\"text\")\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "id": "Itle8wHO5CdM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}