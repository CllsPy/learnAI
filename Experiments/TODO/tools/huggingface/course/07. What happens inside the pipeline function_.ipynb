{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"mount_file_id":"1Dlb7A2l-CokHurX4v7AUC0M1j3t-1xUq","authorship_tag":"ABX9TyPfqYNUV9kYEc1DKHbSr/Nf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## What happens inside the pipeline function?"],"metadata":{"id":"Ey9T4fe_c0Yu"}},{"cell_type":"code","source":["from transformers import pipeline"],"metadata":{"id":"gtVgEbZCdgcb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","classifier = pipeline(\"sentiment-analysis\")"],"metadata":{"id":"0GnYXDzTc4Je"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["classifier([\n","\n","            \"We needed more money but, sad to say, there wasn't any..\",\n","            \"I was glad the movie had a happy ending\"\n","])"],"metadata":{"id":"lvWxoZ8jddB8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import userdata\n","\n","## AutoTokenizer\n","from transformers import AutoTokenizer\n","\n","checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint, token=userdata.get('secretName'))\n","\n","raw_inputs= [\n","\n","            \"We needed more money but, sad to say, there wasn't any..\",\n","            \"I was glad the movie had a happy ending\"\n","]"],"metadata":{"id":"5tPYSZrLeXmp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n","inputs"],"metadata":{"id":"akchx3tce7Ux"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","## Model\n","from transformers import  AutoModel\n","\n","model = AutoModel.from_pretrained(checkpoint)\n","outputs = model(**inputs)"],"metadata":{"id":"4l1sTMyAztjK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(outputs.last_hidden_state.shape) # batch size, sequence length, hidden size"],"metadata":{"id":"a6Vaaig-1DHn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","#Classification\n","from transformers import AutoModelForSequenceClassification\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n","outputs = model(**inputs)"],"metadata":{"id":"rG3F2KMW2Dbo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(outputs.logits)"],"metadata":{"id":"D9CVjslQ2T6u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Processing\n","import torch\n","\n","predictions = torch.nn.functional.softmax(outputs.logits, dim=1)\n","print(predictions)"],"metadata":{"id":"hYaiB3hL27OJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.config.id2label"],"metadata":{"id":"xf8ganHT3GVY"},"execution_count":null,"outputs":[]}]}