{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"mount_file_id":"19S3oMZgwm-BQCcXucO6V66oO-DGS410k","authorship_tag":"ABX9TyM55LqqBptFmv6pnjf4y365"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Datasets\n","<br>\n","\n","- [Aula](https://www.youtube.com/watch?v=_BZearw7f0w&list=PLo2EIpI_JMQvWfQndUesu0nPBAtZ9gP1o&index=20)\n","\n","- [HF datasets](https://huggingface.co/docs/datasets/quickstart)"],"metadata":{"id":"5EpfuKGqGcOK"}},{"cell_type":"code","source":["%%capture\n","!pip install datasets"],"metadata":{"id":"oGh_ttmdHD7Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","from datasets import load_dataset\n","raw_datasets = load_dataset(\"glue\", \"mrpc\")"],"metadata":{"id":"-NlHZ_3WGdUG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["raw_datasets"],"metadata":{"id":"SVeyYI6cHkcH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Acessar data\n","raw_datasets[\"train\"][6]"],"metadata":{"id":"ylte5JTpH7IW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["raw_datasets[\"train\"].features"],"metadata":{"id":"kD9U3KwxJFBO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Tokenizar dataset"],"metadata":{"id":"dBvkZ5E6Jxba"}},{"cell_type":"code","source":["%%capture\n","from transformers import AutoTokenizer\n","\n","checkpoint=\"bert-base-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)"],"metadata":{"id":"Ko6UoTvOJwrq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def tokenizer_function(exemples):\n","  return tokenizer(\n","      exemples[\"sentence1\"], exemples[\"sentence2\"], padding=\"max_length\", truncation=True, max_length=128\n","  )\n","\n","tokenizer_datasets = raw_datasets.map(tokenizer_function, batched=True)"],"metadata":{"id":"8IyUa1qPKDaT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer_datasets = tokenizer_datasets.remove_columns([\"idx\", \"sentence1\", \"sentence2\"])\n","tokenizer_datasets = tokenizer_datasets.rename_column(\"label\", \"labels\")\n","tokenizer_datasets = tokenizer_datasets.with_format(\"torch\")\n","tokenizer_datasets[\"train\"]"],"metadata":{"id":"H_nTIW-MK3cH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jRb7Arm7MOIc"},"execution_count":null,"outputs":[]}]}