{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"mount_file_id":"1NKsf8tb6Rn-n2xVn4TPrEu5OIaQrA1UM","authorship_tag":"ABX9TyOWI0MHHKYmNW0HgzKdVm7/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Pytorch Training Loop\n","<br>\n","\n","- [Aula](https://www.youtube.com/watch?v=Dh9CL8fyG80&list=PLo2EIpI_JMQvWfQndUesu0nPBAtZ9gP1o&index=30)"],"metadata":{"id":"vmm5TtgMXHHh"}},{"cell_type":"code","source":["%%capture\n","!pip install datasets\n","\n","from datasets import load_dataset\n","from transformers import AutoTokenizer, DataCollatorWithPadding\n","\n","raw_datasets = load_dataset(\"glue\", \"mrpc\")\n","checkpoint=\"bert-base-cased\"\n","tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n","\n","def tokenizer_function(exemples):\n","  return tokenizer(exemples[\"sentence1\"], exemples[\"sentence2\"], truncation=True)\n","\n","tokenized_datasets = raw_datasets.map(tokenizer_function, batched=True)\n","tokenized_datasets = tokenized_datasets.remove_columns([\"sentence1\", \"sentence2\", \"idx\"])\n","tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n","tokenized_datasets.set_format(\"torch\")\n","\n","data_collator = DataCollatorWithPadding(tokenizer)"],"metadata":{"id":"Wn8PIASbXIzs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","train_dataloader = DataLoader(\n","    tokenized_datasets[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",")\n","\n","eval_dataloader = DataLoader(\n","    tokenized_datasets[\"validation\"], batch_size=8, collate_fn=data_collator\n",")"],"metadata":{"id":"e6HPoV0Aqdv1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for batch in train_dataloader:\n","  break\n","\n","print({k: v.shape for k, v in batch.items()})"],"metadata":{"id":"D_jQGy6crNkb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModelForSequenceClassification\n","\n","checkpoint=\"bert-base-cased\"\n","model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n"],"metadata":{"id":"gg4r3ndprueZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["outputs = model(**batch)\n","print(outputs.loss, outputs.logits.shape)"],"metadata":{"id":"KVd10YATt2i2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","from transformers import AdamW\n","optimizer = AdamW(model.parameters(), lr=5e-5)"],"metadata":{"id":"LcAC3xb7uA3t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss = outputs.loss\n","loss.backward()\n","optimizer.step()\n","\n","optimizer.zero_grad()"],"metadata":{"id":"pgdYpmaXuVkE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import get_scheduler\n","\n","num_epochs=1\n","num_training_steps = num_epochs * len(train_dataloader)\n","\n","lr_scheduler = get_scheduler(\n","    \"linear\",\n","    optimizer=optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps=num_training_steps\n",")"],"metadata":{"id":"Zq2TqUwWu01R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","print(device)"],"metadata":{"id":"5yTDRXxLvhWF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","!pip install tqdm\n","\n","from tqdm.auto import tqdm"],"metadata":{"id":"JUdZ_mrBwiBa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# progress_bar = tqdm(range(num_training_steps))\n","# model.train()\n","\n","# for epoch in range(num_epochs):\n","#   for batch in train_dataloader:\n","#     bach = {k: v.shape for k, v in batch.items()}\n","#     outputs = model(**batch)\n","#     loss = outputs.loss\n","#     loss.backward()\n","\n","#     optimizer.step()\n","#     lr_scheduler.step()\n","#     optimizer.zero_grad()\n","\n","#     progress_bar.update(1)"],"metadata":{"id":"uv_QcM_vwmJg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from datasets import load_metric\n","\n","# metric = load_metric(\"glue\", \"mrpc\")\n","# model.eval()\n","\n","# for batch in eval_dataloader:\n","#   batch = {k: v.to(device) for k, v in batch.items()}\n","#   with torch.no_grad():\n","#     outputs = model(**batch)\n","\n","#   logits = outputs.logits\n","#   predictions = torch.argmax(logits, dim=-1)\n","#   metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n","\n","# metric.compute()"],"metadata":{"id":"00kLmcTrw-6i"},"execution_count":null,"outputs":[]}]}