{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Em **NLP** a classificação é uma tarefa recorrente, como em:\n",
        "\n",
        "- Identificar se uma avaliação nos comentários da sua loja é positiva ou negativa\n",
        "- Identificar se um dado documento pertence a um determinado autor ou não\n",
        "- Organização de documentos por tópicos/categorias\n",
        "\n",
        "**Referências**\n",
        "\n",
        "- [how make a table markdown](https://www.codecademy.com/resources/docs/markdown/tables)\n",
        "\n",
        "- [class](https://www.youtube.com/watch?v=toUgBQv1BT8&list=PLfYUBJiXbdtSvpQjSnJJ_PmDQB_VyT5iU&index=4)\n",
        "\n",
        "- [deberta](microsoft/deberta-v3-small)\n",
        "\n",
        "- [model for finances analysis sentiment](https://huggingface.co/bardsai/finance-sentiment-pl-fast)"
      ],
      "metadata": {
        "id": "-hEgy5g4uDpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "id": "_8ptDr98VkMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar arquivos\n",
        "path = '/content'\n",
        "!ls {path}"
      ],
      "metadata": {
        "id": "Q2Hthv3y6n8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import basics\n",
        "import pandas as pd\n",
        "\n",
        "trainPath = '/content/drive/MyDrive/Colab Notebooks/Dados/fastai/assets/train.csv'\n",
        "train = pd.read_csv(trainPath)\n",
        "train"
      ],
      "metadata": {
        "id": "82EoiNc4_aAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Existem quadtro bibliotecas principais para \"fazer\" **Data Science** em Python.\n",
        "\n",
        "|     |  |\n",
        "| -------- | ------- |\n",
        "| Numpy  | Numerical Operations    |\n",
        "| Pandas      | DataFrame Manupulation     |\n",
        "| Pytorch    | Neural Nets    |\n",
        "| Matplotlib | Data Visualization\n"
      ],
      "metadata": {
        "id": "e1dDLeNFArAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descrição do dataset\n",
        "train.describe(include='object')"
      ],
      "metadata": {
        "id": "dyVJdSPIF2QC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YO7vrJWmHAT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Única coluna com todas as informações\n",
        "train['input'] = 'TEXT1: ' + train.context + '; TEXT2: ' + train.target + '; ANC1: ' + train.anchor\n",
        "train['input']"
      ],
      "metadata": {
        "id": "ipeyLuszF6wX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "ds = Dataset.from_pandas(train)\n",
        "ds"
      ],
      "metadata": {
        "id": "Me41tIf6HHdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Neural Networks**\n",
        "funcionam com números, elas não são capaz de entender letras, por esse motivo precisamos aplicar uma transformação chamada*Tokenização*."
      ],
      "metadata": {
        "id": "52IyWi84YwOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "## Chamar \"tokenizador\"\n",
        "model_nm = 'microsoft/deberta-v3-small'\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
        "tokz = AutoTokenizer.from_pretrained(model_nm)"
      ],
      "metadata": {
        "id": "WIhaSnPRY85E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demostração\n",
        "tokz.tokenize(\"Meu nome é Carlos.\")"
      ],
      "metadata": {
        "id": "uXq0m1lwZgAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para tokenizar um dataset\n",
        "def tok_func(x): return tokz(x[\"input\"])\n",
        "tok_ds = ds.map(tok_func, batched=True)"
      ],
      "metadata": {
        "id": "tcl9P_pBaW1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row = tok_ds[0]\n",
        "row['input'], row['input_ids']"
      ],
      "metadata": {
        "id": "Dj-eTZoDbvCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformers precisa que tenha uma coluna chamada \"labels\"\n",
        "tok_ds = tok_ds.rename_columns({'score':'labels'})\n",
        "tok_ds"
      ],
      "metadata": {
        "id": "vxzX_Dd9cBje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para avaliar o desempenho do nosso modelo vamos utilizar um conjunto de dados os quais o modelo não não no treino."
      ],
      "metadata": {
        "id": "Pwn8bI7Ql9G0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evalPath = '/content/drive/MyDrive/Colab Notebooks/Dados/fastai/assets/test.csv'\n",
        "eval_df = pd.read_csv(evalPath)\n",
        "eval_df.describe()"
      ],
      "metadata": {
        "id": "P89NqXctf-av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotar função\n",
        "def f(x): return -3*x**2 + 2*x + 20\n",
        "import numpy as np, matplotlib.pyplot as plt\n",
        "\n",
        "def plot_function(f, min=-2.1, max=2.1, color='r'):\n",
        "    x = np.linspace(min,max, 100)[:,None]\n",
        "    plt.plot(x, f(x), color)\n",
        "\n",
        "plot_function(f)"
      ],
      "metadata": {
        "id": "u54nq3pwmaoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Semente de reprodutibilidade\n",
        "from numpy.random import normal,seed,uniform\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "y6ldkcBdm9vL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Noise\n",
        "def noise(x, scale): return normal(scale=scale, size=x.shape)\n",
        "def add_noise(x, mult, add): return x * (1+noise(x,mult)) + noise(x,add)"
      ],
      "metadata": {
        "id": "I4K2FIYBnKbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot\n",
        "\n",
        "x = np.linspace(-2, 2, num=20)[:,None]\n",
        "y = add_noise(f(x), 0.2, 1.3)\n",
        "plt.scatter(x,y);"
      ],
      "metadata": {
        "id": "KfDyiWANnLcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para adequar aos dados\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "def plot_poly(degree):\n",
        "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
        "    model.fit(x, y)\n",
        "    plt.scatter(x,y)\n",
        "    plot_function(model.predict)"
      ],
      "metadata": {
        "id": "ubK_dQuknOM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pouca precisão: Underfiting\n",
        "plot_poly(1)"
      ],
      "metadata": {
        "id": "HHGE2uPcni1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aprendeu bem demais, overfiting\n",
        "\n",
        "plot_poly(10)"
      ],
      "metadata": {
        "id": "Y8x_4_Y9n1vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ideal\n",
        "plot_poly(2)\n",
        "plot_function(f, color='b')"
      ],
      "metadata": {
        "id": "CkNT8CG9n5HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dds = tok_ds.train_test_split(0.25, seed=42)\n",
        "dds"
      ],
      "metadata": {
        "id": "21u8ew6J0bZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como esperado precisamos de uma métrica para avaliar o desempenho do nosso modelos, vamos usar \"r\" ou **Pearson**"
      ],
      "metadata": {
        "id": "SdOYMkSLuZih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Housing Price\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "housing = fetch_california_housing(as_frame=True)\n",
        "housing = housing['data'].join(housing['target']).sample(1000, random_state=52)\n",
        "housing.head()"
      ],
      "metadata": {
        "id": "TwjpvwiVuWDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Relação entre as vairáveis\n",
        "np.set_printoptions(precision=2, suppress=True)\n",
        "np.corrcoef(housing, rowvar=False)"
      ],
      "metadata": {
        "id": "4XoDeug5uZDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlação entre duas colunas\n",
        "def corr(x,y): return np.corrcoef(x,y)[0][1]\n",
        "corr(housing.MedInc, housing.MedHouseVal)"
      ],
      "metadata": {
        "id": "ZcurXkJLuwSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotar correlação\n",
        "def show_corr(df, a, b):\n",
        "    x,y = df[a],df[b]\n",
        "    plt.scatter(x,y, alpha=0.5, s=4)\n",
        "    plt.title(f'{a} vs {b}; r: {corr(x, y):.2f}')\n",
        "\n",
        "show_corr(housing, 'MedInc', 'MedHouseVal')"
      ],
      "metadata": {
        "id": "IqvOr6nmvO36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_corr(housing, 'MedInc', 'AveRooms')"
      ],
      "metadata": {
        "id": "E608RaxWvZh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remover outliers\n",
        "subset = housing[housing.AveRooms<15]\n",
        "show_corr(subset, 'MedInc', 'AveRooms')"
      ],
      "metadata": {
        "id": "JdL9KSSHvmGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular correlação em cada época\n",
        "def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}"
      ],
      "metadata": {
        "id": "P48q3MWix-vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments,Trainer\n",
        "\n",
        "bs = 128\n",
        "epochs = 4\n",
        "\n",
        "lr = 8e-5\n",
        "\n",
        "args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n",
        "    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n",
        "    num_train_epochs=epochs, weight_decay=0.01, report_to='none')"
      ],
      "metadata": {
        "id": "gOxSpounyBvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\n",
        "trainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n",
        "                  tokenizer=tokz, compute_metrics=corr_d)"
      ],
      "metadata": {
        "id": "5M9u1RPXyqQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treino\n",
        "# trainer.train();"
      ],
      "metadata": {
        "id": "y0KxPmgc0hjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Previsão\n",
        "# preds = trainer.predict(eval_ds).predictions.astype(float)\n",
        "# preds"
      ],
      "metadata": {
        "id": "046jiXb90jd5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}