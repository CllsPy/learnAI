{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Lesson 5\n",
        "\n",
        "- 00:00:00 - Introduction\n",
        "- 00:01:59 - Linear model and neural net from scratch\n",
        "- 00:07:30 - Cleaning the data\n",
        "- 00:26:46 - Setting up a linear model\n",
        "- 00:38:48 - Creating functions\n",
        "- 00:39:39 - Doing a gradient descent step\n",
        "- 00:42:15 - Training the linear model\n",
        "- 00:46:05 - Measuring accuracy\n",
        "- 00:48:10 - Using sigmoid\n",
        "- 00:56:09 - Submitting to Kaggle\n",
        "- 00:58:25 - Using matrix product\n",
        "01:03:31 - A neural network\n",
        "- 01:09:20 - Deep learning\n",
        "- 01:12:10 - Linear model final thoughts\n",
        "- 01:15:30 - Why you should use a framework\n",
        "- 01:16:33 - Prep the data\n",
        "- 01:19:38 - Train the model\n",
        "- 01:21:34 - Submit to Kaggle\n",
        "- 01:23:22 - Ensembling\n",
        "01:25:08 - Framework final thoughts\n",
        "- 01:26:44 - How random forests really work\n",
        "- 01:28:57 - Data preprocessing\n",
        "- 01:30:56 - Binary splits\n",
        "- 01:41:34 - Final Roundup\n",
        "\n"
      ],
      "metadata": {
        "id": "m-R57YJ29eFG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear model and neural net from scratch\n",
        "\n",
        "- A função Sigmoid [1] 'transformar' o valor de entrada em uma saída que pode estar entre 0 e 1.\n",
        "\n",
        "- Um neurônio é uma função matemática que dado uma entrada, retorna uama saída, essa saída depende dos parâmetros e da própria entrada, os parâmetros podem ser ajustados.\n",
        "\n",
        "- Uma rede neural é uma conexão entre 'sigmoid functions'.\n",
        "\n",
        "- O processo é que cada camada gera uma saída é chamado de `fowardpropag` [3].\n",
        "\n",
        "- Gradient Descent é um algorítimo que estima onde a função terá seu menor valor [4].\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "**references**\n",
        "\n",
        "[1] [Sigmoid Function](https://en.wikipedia.org/wiki/Sigmoid_function)\n",
        "\n",
        "[2] [Construir Neural Net From Scratch](https://www.freecodecamp.org/news/building-a-neural-network-from-scratch/)\n",
        "\n",
        "[3] [Fowardpropag](https://www.d2l.ai/chapter_multilayer-perceptrons/backprop.html)\n",
        "\n",
        "[4] [Gradient Descent](https://www.khanacademy.org/math/multivariable-calculus/applications-of-multivariable-derivatives/optimizing-multivariable-functions/a/what-is-gradient-descent#:~:text=Gradient%20descent%20minimizes%20differentiable%20functions,direction%20of%20the%20negative%20gradient.)\n",
        "\n",
        "Cálculo Diferencial: https://pt.khanacademy.org/math/differential-calculus\n",
        "\n",
        "Cálculo Integral: https://pt.khanacademy.org/math/integral-calculus\n",
        "\n",
        "Álgebra Linear: https://pt.khanacademy.org/math/linear-algebra\n",
        "\n",
        "Cálculo Mutivariável (Avançando): https://pt.khanacademy.org/math/multivariable-calculus\n",
        "\n"
      ],
      "metadata": {
        "id": "PWFLtmWx-HXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Fuc(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def sigmoid(self, values: list):\n",
        "        plot_values = []\n",
        "        for v in values:\n",
        "            result = 1/(1 + math.exp(-v))\n",
        "            plot_values.append(result)\n",
        "\n",
        "        return plot_values\n",
        "\n",
        "    def plot_fuc(self, values):\n",
        "        list_values = self.sigmoid(values)\n",
        "        plt.plot(self.sigmoid(values))\n",
        "        plt.title('sigmoid function')\n",
        "        plt.ylabel('input')\n",
        "        plt.xlabel('output');\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Test\n",
        "list_values = [-3, -2, -1, 0, 1, 2, 3]\n",
        "f = Fuc()\n",
        "f.plot_fuc(list_values)"
      ],
      "metadata": {
        "id": "y7mubZuY9d02",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural Net\n",
        "import random\n",
        "\n",
        "def input_neuron(x, b):\n",
        "    w = random.uniform(0, 0.5)\n",
        "    print(f'{x*w + b} and {w}')\n",
        "\n",
        "input_neuron(10, 1)"
      ],
      "metadata": {
        "id": "VYYK0iZpx0Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install autograd"
      ],
      "metadata": {
        "id": "5PmYcY6EyaGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Gradient(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    # F(x)\n",
        "    def f(self, a, b, c):\n",
        "        p = np.poly1d([a, b, c])\n",
        "        q = p.deriv()\n",
        "        return q\n",
        "\n",
        "    # Gradient\n",
        "    def gradient(self, a, b, c, lr, x0):\n",
        "        q = self.f(a, b, c)\n",
        "        gd = x0 - (lr * q(x0))\n",
        "        return gd\n",
        "\n",
        "gdc = Gradient()\n",
        "gdc.gradient(1, 0, 0, 0.01, 2)"
      ],
      "metadata": {
        "id": "rXFe8z9Qlz-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = np.poly1d([1, 0, 0])\n",
        "q = p.deriv()\n",
        "\n",
        "p, q(2)"
      ],
      "metadata": {
        "id": "6s-cnbnzNbgw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}