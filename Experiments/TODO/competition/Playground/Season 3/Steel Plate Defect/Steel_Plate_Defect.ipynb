{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/carloscll/votingclassifier-steel-plate-defect?scriptVersionId=170845795\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"id":"ab4122ba","metadata":{"execution":{"iopub.execute_input":"2024-04-07T17:41:59.727172Z","iopub.status.busy":"2024-04-07T17:41:59.726881Z","iopub.status.idle":"2024-04-07T17:42:02.568873Z","shell.execute_reply":"2024-04-07T17:42:02.568026Z"},"papermill":{"duration":2.849564,"end_time":"2024-04-07T17:42:02.571423","exception":false,"start_time":"2024-04-07T17:41:59.721859","status":"completed"},"tags":[]},"outputs":[],"source":["# basics\n","import pandas as pd\n","import numpy as np\n","import scipy.stats as stats\n","import matplotlib.pyplot as plt\n","\n","# sckit\n","from sklearn.linear_model import SGDClassifier\n","from sklearn import metrics\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.naive_bayes import MultinomialNB, GaussianNB\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n","from xgboost.sklearn import XGBClassifier\n","from sklearn.multioutput import MultiOutputClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.compose import ColumnTransformer\n","from sklearn.feature_selection import SelectPercentile, chi2\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.preprocessing import PowerTransformer\n","from sklearn.preprocessing import KBinsDiscretizer\n","from sklearn.decomposition import PCA\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import RobustScaler\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.metrics import accuracy_score\n","\n","# sklearn\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n","from xgboost.sklearn import XGBClassifier\n","from sklearn.feature_selection import RFE\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import ExtraTreesClassifier\n","from sklearn.linear_model import LogisticRegression\n","from xgboost import XGBClassifier\n","from catboost import CatBoostClassifier\n","#from atom import ATOMClassifier\n","\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.naive_bayes import BernoulliNB\n","from sklearn.calibration import CalibratedClassifierCV\n","from sklearn.naive_bayes import CategoricalNB\n","from sklearn.multioutput import ClassifierChain\n","from sklearn.naive_bayes import ComplementNB\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.dummy import DummyClassifier\n","from sklearn.tree import ExtraTreeClassifier\n","from sklearn.ensemble import ExtraTreesClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.gaussian_process import GaussianProcessClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.ensemble import HistGradientBoostingClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.semi_supervised import LabelPropagation\n","from sklearn.semi_supervised import LabelSpreading\n","from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n","from sklearn.svm import LinearSVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.linear_model import LogisticRegressionCV\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.multioutput import MultiOutputClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.neighbors import NearestCentroid\n","from sklearn.svm import NuSVC\n","from sklearn.multiclass import OneVsOneClassifier\n","from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.multiclass import OutputCodeClassifier\n","from sklearn.linear_model import PassiveAggressiveClassifier\n","from sklearn.linear_model import Perceptron\n","from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n","from sklearn.neighbors import RadiusNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import RidgeClassifier\n","from sklearn.linear_model import RidgeClassifierCV\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.svm import SVC\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.feature_selection import SelectKBest, chi2\n","from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n","from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif, f_classif\n","\n","# Reprod\n","SEED = 101\n","\n","# path\n","URL = '/kaggle/input/playground-series-s4e3/train.csv'\n","\n","# targert\n","TARGET_FEATURES = [\n","    \n","                'Pastry', \n","                'Z_Scratch', \n","                'K_Scatch', \n","                'Stains',\n","                'Dirtiness', \n","                'Bumps', \n","                'Other_Faults'\n","    ]\n","\n","\n","# load\n","train = pd.read_csv(URL).set_index('id')\n","#train = train.sample(frac=0.8)"]},{"cell_type":"code","execution_count":2,"id":"fc611608","metadata":{"execution":{"iopub.execute_input":"2024-04-07T17:42:02.580947Z","iopub.status.busy":"2024-04-07T17:42:02.580537Z","iopub.status.idle":"2024-04-07T17:42:14.421804Z","shell.execute_reply":"2024-04-07T17:42:14.421058Z"},"papermill":{"duration":11.848548,"end_time":"2024-04-07T17:42:14.424107","exception":false,"start_time":"2024-04-07T17:42:02.575559","status":"completed"},"tags":[]},"outputs":[],"source":["# seed\n","np.random.seed(SEED)\n","\n","\n","# features and labels\n","X = train.drop(TARGET_FEATURES, axis=1)\n","y = train[TARGET_FEATURES]\n","\n","\n","# train and test\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n","\n","\n","# # models \n","models = {\n","\n","        #'nn': MLPClassifier(max_iter = 1000),\n","        #'lgr': LogisticRegression(max_iter = 1000, random_state=SEED),\n","        #'exc':  ExtraTreesClassifier(random_state=SEED),\n","        #'dtc': DecisionTreeClassifier(random_state=SEED),\n","        'rfc': RandomForestClassifier(random_state=SEED),\n","        #'nbc': GaussianNB(),\n","        'knn': KNeighborsClassifier(),\n","        #'gbc': GradientBoostingClassifier(random_state=SEED),\n","        #'cat': CatBoostClassifier(logging_level='Silent', random_state=SEED),\n","        #'ada': AdaBoostClassifier(random_state=SEED), \n","        #'bgc': BaggingClassifier(random_state=SEED),\n","        #'bnb': BernoulliNB(),\n","        #'dmc': DummyClassifier(random_state=SEED),\n","        #'esc': ExtraTreesClassifier(random_state=SEED),\n","        'gpc': GaussianProcessClassifier(random_state=SEED),\n","        'hgc': HistGradientBoostingClassifier(random_state=SEED),\n","        #'lgc': LogisticRegressionCV(max_iter=1000, random_state=SEED), # BEST\n","        #'mlp': MLPClassifier(max_iter=1000,random_state=SEED),\n","        #'nec': NearestCentroid()\n","    }\n","\n","# estimators = []\n","# estimators.append(('AdaBoostClassifier', AdaBoostClassifier(random_state=13) ))\n","# estimators.append(('Bagging Classifier', BaggingClassifier(random_state=13) ))\n","# estimators.append(('Bernoulli NB', BernoulliNB() ))\n","# estimators.append(('Decision Tree Classifier', DecisionTreeClassifier(random_state=13) ))\n","# estimators.append(('Dummy Classifier', DummyClassifier(random_state=13) ))\n","# estimators.append(('Extra Tree Classifier', ExtraTreeClassifier(random_state=13) ))\n","# estimators.append(('Extra Trees Classifier', ExtraTreesClassifier(random_state=13) ))\n","# estimators.append(('Gaussian NB', GaussianNB() ))\n","# estimators.append(('Gaussian Process Classifier', GaussianProcessClassifier(random_state=13) ))\n","# estimators.append(('Gradient Boosting Classifier', GradientBoostingClassifier(random_state=13) ))\n","# estimators.append(('Hist Gradient Boosting Classifier', HistGradientBoostingClassifier(random_state=13) ))\n","# estimators.append(('KNN', KNeighborsClassifier() ))\n","#estimators.append(('Label Propagation', LabelPropagation() ))\n","#estimators.append(('Label Spreading', LabelSpreading() ))\n","# estimators.append(('LogisticRegression', LogisticRegression(max_iter=1000, random_state=13)))\n","# estimators.append(('Logistic Regression CV', LogisticRegressionCV(max_iter=1000, random_state=13) ))\n","# estimators.append(('MLPClassifier', MLPClassifier(max_iter=2000,random_state=13) ))\n","# estimators.append(('Nearest Centroid', NearestCentroid() ))\n","# estimators.append(('Passive Aggressive Classifier', PassiveAggressiveClassifier(random_state=13) ))\n","# estimators.append(('Perceptron', Perceptron(random_state=13) ))\n","# #estimators.append(('RadiusNeighborsClassifier', RadiusNeighborsClassifier(radius=3) ))\n","# estimators.append(('RandomForest', RandomForestClassifier(max_depth= 10, min_samples_leaf= 1, min_samples_split= 3, n_estimators= 170, random_state=13) ))\n","# estimators.append(('Ridge Classifier', RidgeClassifier(random_state=13) ))\n","# estimators.append(('Ridge Classifier CV', RidgeClassifierCV() ))\n","# estimators.append(('SGDClassifier', SGDClassifier(random_state=13) ))\n","# estimators.append(('SVC', SVC(random_state=13)))\n","# estimators.append(('XGB', XGBClassifier(random_state=13) ))\n","# estimators.append(('CatBoost', CatBoostClassifier(logging_level='Silent', random_state=13) ))\n","#XGB = XGBClassifier(random_state=13)\n","#SC = StackingClassifier(estimators=estimators,final_estimator=XGB,cv=3)\n","\n","def train_eval(models, X_train, X_val, y_train, y_val):\n","    '''\n","    Function to evaluate the\n","    models\n","\n","    models: desired models\n","    X_train: training feature\n","    X_val: validation feature\n","    y_train: training label\n","    y_val: validation label\n","\n","    '''\n","    \n","    numeric_features = X.select_dtypes(exclude=['object']).columns\n","    numeric_transformer = Pipeline(\n","        steps=[\n","              (\"scaler\", StandardScaler()), \n","              #('chi', SelectKBest(score_func=f_classif, k=26))\n","              \n","            ]) \n","    \n","    preprocessor = ColumnTransformer(\n","        transformers=[\n","            (\"num\", numeric_transformer, numeric_features),])\n","            \n","    models_score = {}\n","    for name, model in models.items():\n","        clf = Pipeline(steps=[(\"preprocessor\", preprocessor),(\"classifier\", model)]) # models w/ fe\n","        treinar = MultiOutputClassifier(clf).fit(X_train, y_train) # models wo/ fe\n","        models_score[name] = treinar.score(X_val, y_val)\n","\n","    return models_score\n","\n","\n","#train_eval(models, X_train, X_val, y_train, y_val)\n","\n","# '''\n","# Ensemble\n","# '''\n","# nn_ense = MLPClassifier(max_iter = 1000)\n","# knn_ens = KNeighborsClassifier()\n","# xgb_ens = XGBClassifier()\n","# cat_ens = CatBoostClassifier(logging_level='Silent')\n","# ada_ens = AdaBoostClassifier()\n","\n","rfc_ense = RandomForestClassifier(random_state=SEED)\n","knn_ense = KNeighborsClassifier()\n","gpc_ense = GaussianProcessClassifier(random_state=SEED)\n","hgc_ense = HistGradientBoostingClassifier(random_state=SEED)\n","\n","voting_clf = VotingClassifier(\n","    estimators=[\n","        ('knn', knn_ense),\n","        ('rfc', rfc_ense),\n","        ('gpc', gpc_ense), \n","        ('hgc', hgc_ense)],\n","    \n","    voting='soft')\n","\n","\n","numeric_features = X.select_dtypes(exclude=['object']).columns\n","numeric_transformer = Pipeline(\n","    steps=[(\"scaler\", RobustScaler())]) \n","\n","    \n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        (\"num\", numeric_transformer, numeric_features),])\n","\n","clf = Pipeline(steps=[\n","     (\"preprocessor\", preprocessor),\n","     ('fe', SelectKBest(mutual_info_classif)),\n","     (\"classifier\", knn_ense)])\n","\n","clf_vcl = MultiOutputClassifier(clf).fit(X_train, y_train)    \n","#atom = ATOMClassifier(X_train, y=y_train, verbose=2, random_state=SEED, stratify=False)\n","#atom.run(models=[\"LDA\", \"AdaB\"], metric=\"auc\", n_trials=10)"]},{"cell_type":"markdown","id":"cd37c624","metadata":{"papermill":{"duration":0.002829,"end_time":"2024-04-07T17:42:14.430238","exception":false,"start_time":"2024-04-07T17:42:14.427409","status":"completed"},"tags":[]},"source":["# Display"]},{"cell_type":"code","execution_count":3,"id":"90b41bba","metadata":{"execution":{"iopub.execute_input":"2024-04-07T17:42:14.4373Z","iopub.status.busy":"2024-04-07T17:42:14.437021Z","iopub.status.idle":"2024-04-07T17:42:15.428966Z","shell.execute_reply":"2024-04-07T17:42:15.428033Z"},"papermill":{"duration":0.99808,"end_time":"2024-04-07T17:42:15.431258","exception":false,"start_time":"2024-04-07T17:42:14.433178","status":"completed"},"tags":[]},"outputs":[{"data":{"text/plain":["array([0.72904292, 0.85918379, 0.95243778, 0.93245199, 0.6769994 ,\n","       0.70077315, 0.6114668 ])"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.metrics import roc_auc_score\n","\n","y_hat = clf_vcl.predict_proba(X_val)\n","y_hat = np.transpose([pred[:, 1] for pred in y_hat])\n","roc_auc_score(y_val, y_hat, average=None)"]},{"cell_type":"markdown","id":"8ce2ad75","metadata":{"papermill":{"duration":0.002943,"end_time":"2024-04-07T17:42:15.437711","exception":false,"start_time":"2024-04-07T17:42:15.434768","status":"completed"},"tags":[]},"source":["# Sub"]},{"cell_type":"code","execution_count":4,"id":"38f59bc7","metadata":{"execution":{"iopub.execute_input":"2024-04-07T17:42:15.445473Z","iopub.status.busy":"2024-04-07T17:42:15.445196Z","iopub.status.idle":"2024-04-07T17:42:18.688634Z","shell.execute_reply":"2024-04-07T17:42:18.68772Z"},"papermill":{"duration":3.249812,"end_time":"2024-04-07T17:42:18.690613","exception":false,"start_time":"2024-04-07T17:42:15.440801","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>Pastry</th>\n","      <th>Z_Scratch</th>\n","      <th>K_Scatch</th>\n","      <th>Stains</th>\n","      <th>Dirtiness</th>\n","      <th>Bumps</th>\n","      <th>Other_Faults</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>19219</td>\n","      <td>0.6</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.8</td>\n","      <td>0.6</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>19220</td>\n","      <td>0.6</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.8</td>\n","      <td>0.8</td>\n","      <td>0.6</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>19221</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.6</td>\n","      <td>0.4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>19222</td>\n","      <td>0.8</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.2</td>\n","      <td>0.6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>19223</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.8</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.6</td>\n","      <td>0.8</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>12809</th>\n","      <td>32028</td>\n","      <td>1.0</td>\n","      <td>0.8</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.8</td>\n","      <td>1.0</td>\n","      <td>0.4</td>\n","    </tr>\n","    <tr>\n","      <th>12810</th>\n","      <td>32029</td>\n","      <td>0.8</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.8</td>\n","      <td>0.8</td>\n","      <td>0.8</td>\n","    </tr>\n","    <tr>\n","      <th>12811</th>\n","      <td>32030</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>12812</th>\n","      <td>32031</td>\n","      <td>0.8</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.6</td>\n","      <td>0.8</td>\n","    </tr>\n","    <tr>\n","      <th>12813</th>\n","      <td>32032</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.2</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>12814 rows × 8 columns</p>\n","</div>"],"text/plain":["          id  Pastry  Z_Scratch  K_Scatch  Stains  Dirtiness  Bumps  \\\n","0      19219     0.6        1.0       1.0     1.0        1.0    0.8   \n","1      19220     0.6        1.0       1.0     1.0        0.8    0.8   \n","2      19221     1.0        1.0       1.0     1.0        1.0    0.6   \n","3      19222     0.8        1.0       1.0     1.0        1.0    0.2   \n","4      19223     1.0        1.0       0.8     1.0        1.0    0.6   \n","...      ...     ...        ...       ...     ...        ...    ...   \n","12809  32028     1.0        0.8       1.0     1.0        0.8    1.0   \n","12810  32029     0.8        1.0       1.0     1.0        0.8    0.8   \n","12811  32030     1.0        1.0       0.0     1.0        1.0    1.0   \n","12812  32031     0.8        1.0       1.0     1.0        1.0    0.6   \n","12813  32032     1.0        1.0       0.2     1.0        1.0    1.0   \n","\n","       Other_Faults  \n","0               0.6  \n","1               0.6  \n","2               0.4  \n","3               0.6  \n","4               0.8  \n","...             ...  \n","12809           0.4  \n","12810           0.8  \n","12811           1.0  \n","12812           0.8  \n","12813           0.8  \n","\n","[12814 rows x 8 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["np.random.seed(101)\n","\n","test = pd.read_csv('/kaggle/input/playground-series-s4e3/test.csv').set_index('id')\n","sub = pd.read_csv('/kaggle/input/playground-series-s4e3/sample_submission.csv')\n","\n","predicted_probabilities = clf_vcl.predict_proba(test)  \n","for i, col in enumerate(sub.columns[1:]):\n","    sub[col] = predicted_probabilities[i]\n","\n","sub"]},{"cell_type":"code","execution_count":5,"id":"d1fb2fd9","metadata":{"execution":{"iopub.execute_input":"2024-04-07T17:42:18.699108Z","iopub.status.busy":"2024-04-07T17:42:18.69878Z","iopub.status.idle":"2024-04-07T17:42:18.791518Z","shell.execute_reply":"2024-04-07T17:42:18.790794Z"},"papermill":{"duration":0.0993,"end_time":"2024-04-07T17:42:18.793642","exception":false,"start_time":"2024-04-07T17:42:18.694342","status":"completed"},"tags":[]},"outputs":[],"source":["sub.to_csv('26_knn.csv', index=False)"]},{"cell_type":"markdown","id":"d2e7c14d","metadata":{"papermill":{"duration":0.003444,"end_time":"2024-04-07T17:42:18.800933","exception":false,"start_time":"2024-04-07T17:42:18.797489","status":"completed"},"tags":[]},"source":["# Refs\n","\n","\n","[Feature Selection: Select Best](https://medium.com/@Kavya2099/optimizing-performanace-selectkbest-for-efficient-feature-selection-in-machine-learning-3b635905ed48)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":7659021,"sourceId":68699,"sourceType":"competition"}],"dockerImageVersionId":30664,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":22.300589,"end_time":"2024-04-07T17:42:19.222077","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-07T17:41:56.921488","version":"2.5.0"}},"nbformat":4,"nbformat_minor":5}
